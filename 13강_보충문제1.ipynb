{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjEldW/Au5Ml3gZ2ZDk2nR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hr7git/Data-Analysis-with-Open-Source/blob/main/13%EA%B0%95_%EB%B3%B4%EC%B6%A9%EB%AC%B8%EC%A0%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ4pjw8iuObZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**'13강 반정형 데이터 분석'** 파일은 웹 크롤링(Selenium)부터 텍스트 전처리, 키워드 분석(WordCloud), 그리고 LLM을 이용한 분류까지 담고 있는 아주 알찬 내용입니다.\n",
        "\n",
        "초보자들에게는 웹 페이지를 긁어오는 '수집' 단계와 텍스트를 요리하는 '분석' 단계를 나누어 숙제를 내주는 것이 좋습니다. 사용자님의 배경을 고려해 **[수집 -> 정제 -> 시각화]**의 3단계 숙제와 함수 설명서를 정리해 드립니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 📝 13강 기반: 초보자를 위한 3단계 빌드업 숙제\n",
        "\n",
        "#### [숙제 1] 웹에서 데이터 \"낚시\"하기 (수집)\n",
        "\n",
        "**목표:** 웹사이트의 복잡한 HTML 구조 속에서 내가 원하는 '글 제목'만 뽑아내는 능력을 기릅니다.\n",
        "\n",
        "* **문제:** 아래 빈칸을 채워 웹 페이지의 모든 '제목' 텍스트를 리스트에 담으세요.\n",
        "\n",
        "```python\n",
        "from lxml import etree\n",
        "\n",
        "# html_content에 웹 페이지 소스가 저장되어 있다고 가정합니다.\n",
        "root = etree.fromstring(html_content)\n",
        "\n",
        "### [숙제] XPath를 사용하여 '제목'이 들어있는 <a> 태그들을 모두 찾으세요.\n",
        "# 힌트: //a[@class='title'] 와 같은 형식을 사용합니다.\n",
        "titles = root.xpath(\"_________________________________\")\n",
        "\n",
        "# 제목 텍스트만 추출해서 리스트로 만들기\n",
        "title_list = [t.text.strip() for t in titles]\n",
        "print(title_list[:5])\n",
        "\n",
        "```\n",
        "\n",
        "#### [숙제 2] 불필요한 글자 \"청소\"하기 (전처리)\n",
        "\n",
        "**목표:** 정규표현식을 사용하여 텍스트 데이터에 섞여 있는 특수문자나 공백을 제거합니다.\n",
        "\n",
        "* **문제:** 제목 데이터에서 특수문자를 제거하고 한글만 남기는 함수를 완성하세요.\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    ### [숙제] 정규표현식을 사용하여 한글과 공백을 제외한 모든 문자를 제거하세요.\n",
        "    # 힌트: [^가-힣\\s] 패턴을 사용하여 re.sub로 교체합니다.\n",
        "    cleaned = re.sub(r\"________________\", \"\", text)\n",
        "    return cleaned.strip()\n",
        "\n",
        "sample = \"안녕! 하세요? [공지사항]입니다.\"\n",
        "print(f\"결과: {clean_text(sample)}\")\n",
        "\n",
        "```\n",
        "\n",
        "#### [숙제 3] 핵심 키워드 \"구름\" 만들기 (시각화)\n",
        "\n",
        "**목표:** 어떤 단어가 가장 많이 등장했는지 한눈에 보여주는 워드클라우드를 생성합니다.\n",
        "\n",
        "* **문제:** 단어 빈도수(counts)를 이용하여 워드클라우드를 생성하고 화면에 출력하세요.\n",
        "\n",
        "```python\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = {'데이터': 10, '분석': 8, '파이썬': 15, '경제': 5}\n",
        "\n",
        "### [숙제] WordCloud 객체를 생성하고 그림을 그리세요.\n",
        "# 힌트: .generate_from_frequencies()를 사용합니다.\n",
        "wc = WordCloud(font_path='nanum', background_color='white')\n",
        "cloud = wc.________________(counts)\n",
        "\n",
        "plt.imshow(cloud)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 📑 13강 주요 함수 상세 설명서\n",
        "\n",
        "#### 1. `etree.fromstring()` & `xpath()`\n",
        "\n",
        "* **설명:** 웹 페이지(HTML)를 컴퓨터가 이해할 수 있는 트리 구조로 바꾼 뒤, 주소(XPath)를 이용해 특정 데이터를 찾아냅니다.\n",
        "* **비유:** 거대한 도서관(`HTML`)에서 내가 원하는 책(`데이터`)이 있는 서가 번호(`XPath`)를 찾아가는 과정입니다.\n",
        "\n",
        "#### 2. `re.sub(pattern, repl, string)`\n",
        "\n",
        "* **설명:** 정규표현식(Regex)을 사용하여 특정 패턴의 문자열을 찾아 다른 글자로 바꿉니다.\n",
        "* **수학적 의미:** 텍스트 집합에서 노이즈()를 제거하는 함수적 매핑 과정입니다. '한글만 남겨라'라는 필터를 통과시키는 것과 같습니다.\n",
        "\n",
        "#### 3. `Konlpy`의 `nouns()`\n",
        "\n",
        "* **설명:** 한국어 문장에서 '명사'만 골라냅니다.\n",
        "* **중요성:** 문장에서 '은/는/이/가' 같은 조사는 분석에 방해가 됩니다. 의미를 담고 있는 핵심 단어(명사)만 뽑아내는 것이 분석의 첫걸음입니다.\n",
        "\n",
        "#### 4. `WordCloud.generate_from_frequencies()`\n",
        "\n",
        "* **설명:** 단어의 빈도수에 비례하여 단어의 크기를 다르게 그려주는 시각화 함수입니다.\n",
        "* **데이터적 의미:** 빈도라는 통계적 수치를 '크기'라는 시각적 요소로 변환하여 데이터의 밀도를 한눈에 보여줍니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 초보자 가이드 팁\n",
        "\n",
        "초보자들에게 13강을 가르칠 때는 **\"우리가 보는 웹 화면 뒤에는 뼈대(HTML)가 있고, AI는 그 뼈대 사이의 글자를 먹고 산다\"**는 개념을 먼저 심어주세요.\n",
        "\n",
        "사용자님이 SQL을 다루시니, **\"XPath는 HTML 버전의 SELECT 문이다\"**라고 설명해주시면 훨씬 빨리 이해할 것입니다."
      ],
      "metadata": {
        "id": "04PQi1PVuP3S"
      }
    }
  ]
}